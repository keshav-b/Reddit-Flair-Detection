{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Reddit's API, PRAW to scrap subreddits, and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the Reddit object with user's credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = \"udo3Q8u5ZjWoTw\", \n",
    "                     client_secret = \"yNiOW6McpesaIbhiJjMeM-zlH_U\", \n",
    "                     user_agent = \"Testing_api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the subreddit of r/india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subred = reddit.subreddit('india')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considering \"hot\", \"top\", \"new\" and \"controversial\" filters to scrap subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot = subred.hot(limit=3000)\n",
    "top = subred.top(limit=3000)\n",
    "controversial = subred.controversial(limit=3000)\n",
    "new = subred.new(limit=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "praw.models.listing.generator.ListingGenerator"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilizing a dictionary \"data\" to store the scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"id\":[], \"url\":[],\"title\":[],  \"body\":[], \"flair\":[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from corresponding filtered subreddits and appending in \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hot:\n",
    "    \n",
    "    data['id'].append(i.id)\n",
    "    data['url'].append(i.url)\n",
    "    data['title'].append(i.title)\n",
    "    data['body'].append(i.selftext)    \n",
    "    data['flair'].append(i.link_flair_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top:\n",
    "    \n",
    "    data['id'].append(i.id)\n",
    "    data['url'].append(i.url)\n",
    "    data['title'].append(i.title)\n",
    "    data['body'].append(i.selftext)    \n",
    "    data['flair'].append(i.link_flair_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in controversial:\n",
    "    \n",
    "    data['id'].append(i.id)\n",
    "    data['url'].append(i.url)\n",
    "    data['title'].append(i.title)\n",
    "    data['body'].append(i.selftext)    \n",
    "    data['flair'].append(i.link_flair_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new:\n",
    "    \n",
    "    data['id'].append(i.id)\n",
    "    data['url'].append(i.url)\n",
    "    data['title'].append(i.title)\n",
    "    data['body'].append(i.selftext)    \n",
    "    data['flair'].append(i.link_flair_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the dictionary to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1zi21</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g1zi21...</td>\n",
       "      <td>Coronavirus (COVID-19) Megathread - News and U...</td>\n",
       "      <td>###[Covid-19 Fundraisers &amp; Donation Links](htt...</td>\n",
       "      <td>Coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g4d2ix</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g4d2ix...</td>\n",
       "      <td>[Monthly Happiness Thread] Randians, please sh...</td>\n",
       "      <td>&lt;3         \\n          \\nLinks:               ...</td>\n",
       "      <td>Scheduled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g4olq1</td>\n",
       "      <td>https://i.redd.it/tt6t9rjqhxt41.jpg</td>\n",
       "      <td>Was going through my grandpa’s stuffs and foun...</td>\n",
       "      <td></td>\n",
       "      <td>Non-Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g4oun2</td>\n",
       "      <td>https://i.redd.it/fvgic0milxt41.jpg</td>\n",
       "      <td>Brutal Palghar lynching during Corona lockdown...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g4mzra</td>\n",
       "      <td>https://science.thewire.in/environment/ganga-r...</td>\n",
       "      <td>The Lockdown Cleaned the Ganga More Than ‘Nama...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                                url  \\\n",
       "0  g1zi21  https://www.reddit.com/r/india/comments/g1zi21...   \n",
       "1  g4d2ix  https://www.reddit.com/r/india/comments/g4d2ix...   \n",
       "2  g4olq1                https://i.redd.it/tt6t9rjqhxt41.jpg   \n",
       "3  g4oun2                https://i.redd.it/fvgic0milxt41.jpg   \n",
       "4  g4mzra  https://science.thewire.in/environment/ganga-r...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Coronavirus (COVID-19) Megathread - News and U...   \n",
       "1  [Monthly Happiness Thread] Randians, please sh...   \n",
       "2  Was going through my grandpa’s stuffs and foun...   \n",
       "3  Brutal Palghar lynching during Corona lockdown...   \n",
       "4  The Lockdown Cleaned the Ganga More Than ‘Nama...   \n",
       "\n",
       "                                                body          flair  \n",
       "0  ###[Covid-19 Fundraisers & Donation Links](htt...    Coronavirus  \n",
       "1  <3         \\n          \\nLinks:               ...      Scheduled  \n",
       "2                                                     Non-Political  \n",
       "3                                                          Politics  \n",
       "4                                                          Politics  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3618, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since subreddits can appear in multiple filters, the DF is sorted and duplicate elements are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"id\", inplace = True)\n",
    "df.drop_duplicates(subset =\"id\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2846, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the unique flairs and their frequencies from the collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                          931\n",
       "Non-Political                     783\n",
       "Coronavirus                       400\n",
       "AskIndia                          190\n",
       "[R]eddiquette                      71\n",
       "Policy/Economy                     60\n",
       "Photography                        52\n",
       "Business/Finance                   40\n",
       "Sports                             38\n",
       "Science/Technology                 30\n",
       "Food                               23\n",
       "Unverified                         19\n",
       "Scheduled                          11\n",
       "CAA-NRC                            11\n",
       "Moderated                           7\n",
       "CAA-NRC-NPR                         6\n",
       "Misleading                          6\n",
       "Policy                              4\n",
       "Demonetization                      4\n",
       "Entertainment                       3\n",
       "Policy & Economy                    3\n",
       "r/all                               3\n",
       "AMA                                 2\n",
       "/r/all                              2\n",
       "Original Content :)                 1\n",
       "Lifehacks                           1\n",
       "Goal Achieved!!!                    1\n",
       "40 Martyrs                          1\n",
       "Meta                                1\n",
       "Politics [Megathread]               1\n",
       "AMA Concluded                       1\n",
       "Politics -- Source in comments      1\n",
       "Old                                 1\n",
       "[Editorialised]                     1\n",
       "OC                                  1\n",
       "Totally real                        1\n",
       "Policy/Economy -2017 Article        1\n",
       "Original Comics                     1\n",
       "| Repost |                          1\n",
       "On Internet Shutdowns               1\n",
       "Zoke Tyme                           1\n",
       "Politics [OLD]                      1\n",
       "Science & Technology                1\n",
       "Misleading Headline                 1\n",
       "Official Sadness Thread             1\n",
       "Name: flair, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['flair'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the top 10 flairs from the scrapped list as the categories for the succeeding prediction task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_flairs = [\"Politics\", \"Non-Political\", \"Coronavirus\", \"AskIndia\", \"Policy/Economy\", \"[R]eddiquette\", \n",
    "              \"Photography\", \"Business/Finance\", \"Sports\", \"Science/Technology\"]\n",
    "\n",
    "df_top = df.loc[df['flair'].isin(top_flairs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2595, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>1vfqzr</td>\n",
       "      <td>http://www.bollywoodmantra.com/news/hrithik-ro...</td>\n",
       "      <td>Hrithik Roshan to tie the knot for the second ...</td>\n",
       "      <td></td>\n",
       "      <td>Non-Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>1vgb3k</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/1vgb3k...</td>\n",
       "      <td>Girls of /r/India, would any of you be interes...</td>\n",
       "      <td>.</td>\n",
       "      <td>Non-Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>1vqu7l</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/1vqu7l...</td>\n",
       "      <td>Regarding the ongoing Kejru dramabaaz</td>\n",
       "      <td>I spoke with some people in Delhi , one of who...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>1w4xsp</td>\n",
       "      <td>http://bjpscams.com/</td>\n",
       "      <td>A site that lists out scams by the BJP</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>1wcra7</td>\n",
       "      <td>http://www.truthofgujarat.com/modi-says-india-...</td>\n",
       "      <td>Modi says India has no War Memorials, here's a...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                                url  \\\n",
       "2333  1vfqzr  http://www.bollywoodmantra.com/news/hrithik-ro...   \n",
       "2150  1vgb3k  https://www.reddit.com/r/india/comments/1vgb3k...   \n",
       "2301  1vqu7l  https://www.reddit.com/r/india/comments/1vqu7l...   \n",
       "2264  1w4xsp                               http://bjpscams.com/   \n",
       "2122  1wcra7  http://www.truthofgujarat.com/modi-says-india-...   \n",
       "\n",
       "                                                  title  \\\n",
       "2333  Hrithik Roshan to tie the knot for the second ...   \n",
       "2150  Girls of /r/India, would any of you be interes...   \n",
       "2301              Regarding the ongoing Kejru dramabaaz   \n",
       "2264             A site that lists out scams by the BJP   \n",
       "2122  Modi says India has no War Memorials, here's a...   \n",
       "\n",
       "                                                   body          flair  \n",
       "2333                                                     Non-Political  \n",
       "2150                                                  .  Non-Political  \n",
       "2301  I spoke with some people in Delhi , one of who...       Politics  \n",
       "2264                                                          Politics  \n",
       "2122                                                          Politics  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the data is skewed towards certain flairs and not others, we are scrapping again from the r/india subreddit for the above mentioned flairs with a limit of 100 for each flairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = \"udo3Q8u5ZjWoTw\", \n",
    "                     client_secret = \"yNiOW6McpesaIbhiJjMeM-zlH_U\", \n",
    "                     user_agent = \"Testing_api\")\n",
    "\n",
    "subred = reddit.subreddit('india')\n",
    "sample_data = {\"id\":[], \"url\":[], \"title\":[], \"body\":[], \"flair\":[]}\n",
    "\n",
    "top_flairs = [\"Politics\", \"Non-Political\", \"Coronavirus\", \"AskIndia\", \"Policy/Economy\", \"[R]eddiquette\", \n",
    "              \"Photography\", \"Business/Finance\", \"Sports\", \"Science/Technology\"]\n",
    "\n",
    "for flair in top_flairs:\n",
    "  \n",
    "  top_f = subred.search(flair, limit=100)\n",
    "  \n",
    "  for i in top_f:\n",
    "    \n",
    "    sample_data[\"id\"].append(i.id)\n",
    "    sample_data[\"url\"].append(i.url)\n",
    "    sample_data[\"title\"].append(i.title)\n",
    "    sample_data[\"body\"].append(i.selftext)\n",
    "    sample_data[\"flair\"].append(flair)\n",
    "    \n",
    "sample = pd.DataFrame(sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g2ct57</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g2ct57...</td>\n",
       "      <td>A polite request to all Indians here</td>\n",
       "      <td>I don't know if it is the same situation in ot...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>futac9</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/futac9...</td>\n",
       "      <td>Pitting a community against a political party ...</td>\n",
       "      <td>First of all let me start by saying it was stu...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ff8sth</td>\n",
       "      <td>https://i.redd.it/yjo9wpy38el41.jpg</td>\n",
       "      <td>A new political party gave a full front page a...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fpaj1w</td>\n",
       "      <td>https://theprint.in/india/hit-by-backlash-over...</td>\n",
       "      <td>Hit by backlash over posts on lack of medical ...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fxs1vy</td>\n",
       "      <td>https://www.timesnownews.com/india/article/pol...</td>\n",
       "      <td>Politics in the time of corona: WB CM question...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                                url  \\\n",
       "0  g2ct57  https://www.reddit.com/r/india/comments/g2ct57...   \n",
       "1  futac9  https://www.reddit.com/r/india/comments/futac9...   \n",
       "2  ff8sth                https://i.redd.it/yjo9wpy38el41.jpg   \n",
       "3  fpaj1w  https://theprint.in/india/hit-by-backlash-over...   \n",
       "4  fxs1vy  https://www.timesnownews.com/india/article/pol...   \n",
       "\n",
       "                                               title  \\\n",
       "0               A polite request to all Indians here   \n",
       "1  Pitting a community against a political party ...   \n",
       "2  A new political party gave a full front page a...   \n",
       "3  Hit by backlash over posts on lack of medical ...   \n",
       "4  Politics in the time of corona: WB CM question...   \n",
       "\n",
       "                                                body     flair  \n",
       "0  I don't know if it is the same situation in ot...  Politics  \n",
       "1  First of all let me start by saying it was stu...  Politics  \n",
       "2                                                     Politics  \n",
       "3                                                     Politics  \n",
       "4                                                     Politics  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flair\n",
      "AskIndia              100\n",
      "Business/Finance      100\n",
      "Coronavirus           100\n",
      "Non-Political         100\n",
      "Photography           100\n",
      "Policy/Economy        100\n",
      "Politics              100\n",
      "Science/Technology    100\n",
      "Sports                100\n",
      "[R]eddiquette          18\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = sample.groupby('flair')['id'].nunique()\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is seen that \"[R]eddiquette\"  flair has less samples so, using the previously scrapped data and concatinating for    \"[R]eddiquette\" alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>1xseo5</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/1xseo5...</td>\n",
       "      <td>TIL. Lord Shiva encourages [r]itual rape prost...</td>\n",
       "      <td>Wendy Doniger, has tried to bring forth many r...</td>\n",
       "      <td>[R]eddiquette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>1zf5ln</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/1zf5ln...</td>\n",
       "      <td>Modi - No [R]iots in Gujarat in last 10 years ...</td>\n",
       "      <td>1) [Vadodara: Centre sends para-military help]...</td>\n",
       "      <td>[R]eddiquette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>217pd5</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/217pd5...</td>\n",
       "      <td>New Mod Announcement [R]</td>\n",
       "      <td>We are happy to announce the addition of /u/Aw...</td>\n",
       "      <td>[R]eddiquette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>254794</td>\n",
       "      <td>https://pbs.twimg.com/media/BnIaNqtCUAAU8l7.jpg</td>\n",
       "      <td>A 12-year-old happy child showing the flowe[r]...</td>\n",
       "      <td></td>\n",
       "      <td>[R]eddiquette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>2c0sze</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/2c0sze...</td>\n",
       "      <td>[R] Where is the Muslim outrage?</td>\n",
       "      <td>For the past few weeks, I have been observing ...</td>\n",
       "      <td>[R]eddiquette</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                                url  \\\n",
       "1842  1xseo5  https://www.reddit.com/r/india/comments/1xseo5...   \n",
       "2293  1zf5ln  https://www.reddit.com/r/india/comments/1zf5ln...   \n",
       "1788  217pd5  https://www.reddit.com/r/india/comments/217pd5...   \n",
       "2524  254794    https://pbs.twimg.com/media/BnIaNqtCUAAU8l7.jpg   \n",
       "1953  2c0sze  https://www.reddit.com/r/india/comments/2c0sze...   \n",
       "\n",
       "                                                  title  \\\n",
       "1842  TIL. Lord Shiva encourages [r]itual rape prost...   \n",
       "2293  Modi - No [R]iots in Gujarat in last 10 years ...   \n",
       "1788                           New Mod Announcement [R]   \n",
       "2524  A 12-year-old happy child showing the flowe[r]...   \n",
       "1953                   [R] Where is the Muslim outrage?   \n",
       "\n",
       "                                                   body          flair  \n",
       "1842  Wendy Doniger, has tried to bring forth many r...  [R]eddiquette  \n",
       "2293  1) [Vadodara: Centre sends para-military help]...  [R]eddiquette  \n",
       "1788  We are happy to announce the addition of /u/Aw...  [R]eddiquette  \n",
       "2524                                                     [R]eddiquette  \n",
       "1953  For the past few weeks, I have been observing ...  [R]eddiquette  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r = df[df['flair'] == '[R]eddiquette']\n",
    "df_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([sample, df_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g2ct57</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g2ct57...</td>\n",
       "      <td>A polite request to all Indians here</td>\n",
       "      <td>I don't know if it is the same situation in ot...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>futac9</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/futac9...</td>\n",
       "      <td>Pitting a community against a political party ...</td>\n",
       "      <td>First of all let me start by saying it was stu...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ff8sth</td>\n",
       "      <td>https://i.redd.it/yjo9wpy38el41.jpg</td>\n",
       "      <td>A new political party gave a full front page a...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fpaj1w</td>\n",
       "      <td>https://theprint.in/india/hit-by-backlash-over...</td>\n",
       "      <td>Hit by backlash over posts on lack of medical ...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fxs1vy</td>\n",
       "      <td>https://www.timesnownews.com/india/article/pol...</td>\n",
       "      <td>Politics in the time of corona: WB CM question...</td>\n",
       "      <td></td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                                url  \\\n",
       "0  g2ct57  https://www.reddit.com/r/india/comments/g2ct57...   \n",
       "1  futac9  https://www.reddit.com/r/india/comments/futac9...   \n",
       "2  ff8sth                https://i.redd.it/yjo9wpy38el41.jpg   \n",
       "3  fpaj1w  https://theprint.in/india/hit-by-backlash-over...   \n",
       "4  fxs1vy  https://www.timesnownews.com/india/article/pol...   \n",
       "\n",
       "                                               title  \\\n",
       "0               A polite request to all Indians here   \n",
       "1  Pitting a community against a political party ...   \n",
       "2  A new political party gave a full front page a...   \n",
       "3  Hit by backlash over posts on lack of medical ...   \n",
       "4  Politics in the time of corona: WB CM question...   \n",
       "\n",
       "                                                body     flair  \n",
       "0  I don't know if it is the same situation in ot...  Politics  \n",
       "1  First of all let me start by saying it was stu...  Politics  \n",
       "2                                                     Politics  \n",
       "3                                                     Politics  \n",
       "4                                                     Politics  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flair\n",
      "AskIndia              100\n",
      "Business/Finance      100\n",
      "Coronavirus           100\n",
      "Non-Political         100\n",
      "Photography           100\n",
      "Policy/Economy        100\n",
      "Politics              100\n",
      "Science/Technology    100\n",
      "Sports                100\n",
      "[R]eddiquette          89\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = final.groupby('flair')['id'].nunique()\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Converting the DataFrame into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('Data/reddit-top-flairs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
